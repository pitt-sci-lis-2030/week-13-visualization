{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations, or visual represenations of data, are a powerful way to represent relationships of data in a way that humans can more effectively understand compared to textual data representations.  In this lecture, we will give a brief introduction to some of the basic visualization capabilities that are available in Python (with and without Pandas).  If you are interested more broadly in data visualization, you should consider LIS 2690 or CMPINF 2130 (offered this summer!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathplotlib provides A LOT of functionality similar tothe charing features in Excel, but with a lot more control.  It also integrates will with Pandas.\n",
    "\n",
    "Examples of all the visualizations can be found [here](https://matplotlib.org/3.1.1/gallery/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats # <-- Use for some simple stats\n",
    "\n",
    "import numpy as np  # <-- this is NumPy, used for numerical computing, we're not going to get in to it, but many of the examples use this package as helpers for the plotting code\n",
    "\n",
    "import matplotlib.pyplot as plt # <-- MatPlotLib is one of the most used graphing packages used in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's jump in and load up a simple dataframe.  This is dataframe has information about a a drug trial and a measure of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"files/drug.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the set_index method to set the index of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('person')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the replace function replace the number values with the meaning of the dosing categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dose'].replace({1: 'placebo', 2: 'low', 3: 'high'}, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use some of the simple statistics capabilities to help us get simple stats... we'll see later how this is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['dose'] == 'placebo'\n",
    "\n",
    "df[mask].mean()['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask].std()['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this is what I was struggling to show last week in the Activities... you can put the mask right in to the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['dose'] == 'placebo'].mean()['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now let's get in to some plotting --- let's create a simple bar chart for the placebo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "N = 1\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35         # the width of the bars\n",
    "\n",
    "means = df[df['dose'] == 'placebo'].mean()['result']\n",
    "std = df[df['dose'] == 'placebo'].std()['result']\n",
    "\n",
    "ax.bar(ind, means , width, bottom=0, yerr=std)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend this approach to also include additional bars, with additional data.\n",
    "\n",
    "Pay careful attention to how we define the X and Y variables.  We've seen this way of arrangin data before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "N = 3\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35         # the width of the bars\n",
    "\n",
    "means = [df[df['dose'] == 'placebo'].mean()['result'], df[df['dose'] == 'low'].mean()['result'], df[df['dose'] == 'high'].mean()['result']]\n",
    "std = [df[df['dose'] == 'placebo'].std()['result'], df[df['dose'] == 'low'].std()['result'], df[df['dose'] == 'high'].std()['result']]\n",
    "\n",
    "ax.bar(ind, means , width, bottom=0, yerr=std)\n",
    "plt.title('Result by group')\n",
    "plt.xticks(ind, ('Placebo', \"Low Dose\", \"High Dose\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because MatPlotLib takes simple lists, we can send data NOT from Pandas just as easily!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "N = 3\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35         # the width of the bars\n",
    "\n",
    "means = [2,3,2]\n",
    "std = [1,1,1]\n",
    "\n",
    "ax.bar(ind, means , width, bottom=0, yerr=std)\n",
    "plt.title('Result by group')\n",
    "plt.xticks(ind, ('Placebo', \"Low Dose\", \"High Dose\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's not just bar charts!\n",
    "\n",
    "We can use the same data, but with a different type of plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1, 5, 5)\n",
    "y = df[df['dose'] == 'placebo']['result'].sort_values()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Using set_dashes() to modify dashing of an existing line\n",
    "line1 = ax.plot(x, y, dashes=[2, 2, 10, 2], label='Placebo')\n",
    "                      # 2pt line, 2pt break, 10pt line, 2pt break\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the bar charts, we can add more lines.  In this case we add more line descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Using set_dashes() to modify dashing of an existing line\n",
    "line1 = ax.plot(x, y, dashes=[2, 2, 10, 2], label='Placebo')\n",
    "                      # 2pt line, 2pt break, 10pt line, 2pt break\n",
    "\n",
    "x2 = np.linspace(1, 5, 5)\n",
    "y2 = df[df['dose'] == 'low']['result'].sort_values()\n",
    "\n",
    "# Using plot(..., dashes=...) to set the dashing when creating a line\n",
    "line2 = ax.plot(x2, y2, dashes=[6, 2], label='Low')\n",
    "\n",
    "\n",
    "x3 = np.linspace(1, 5, 5)\n",
    "y3 = df[df['dose'] == 'high']['result'].sort_values()\n",
    "\n",
    "line3 = ax.plot(x3, y3, dashes=[20, 2], label='High')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting with multiple data sets\n",
    "\n",
    "Let's start by creating a merged data set.  Lots of steps here, but let's walk thorugh it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obesity = pd.read_csv(\"files/obesity-ac-2006-2010censustracts.csv\")\n",
    "df_obesity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fast_food_tract = pd.read_csv(\"files/fastfoodalleghenycountyupdatexy2plustract.csv\")\n",
    "df_fast_food_tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fast_food_tract = df_fast_food_tract.dropna(subset=['tract'])\n",
    "df_fast_food_tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fast_food_tract['tract'] = df_fast_food_tract['tract'].astype('int32')\n",
    "df_fast_food_tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fast_food_tract_count = df_fast_food_tract.groupby('tract').count()\n",
    "df_fast_food_tract_count = df_fast_food_tract_count.drop(['Name', 'Street Name', 'Legal Name', 'Start Date', 'Street Number', 'ZIP Code', 'Lat', 'Lon', 'Category'], axis=1).rename(columns={'Unnamed: 0' : 'count'})\n",
    "df_fast_food_tract_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_obesity, df_fast_food_tract_count, left_on='2000 Tract', right_on = 'tract', how='inner')\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = df_merged.plot.scatter(x='count', y='2006-2010 estimate of obesity',c='DarkBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes, there is a clear outlier (Dahntahn!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_no_outlier = df_merged.drop(1, axis=0)\n",
    "ax2 = df_merged_no_outlier.plot.scatter(x='count', y='2006-2010 estimate of obesity',c='DarkBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's get fancy and add some histograms for each of the axis.  Recall, a historgram is a way of visualing one-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_merged_no_outlier['count']\n",
    "y = df_merged_no_outlier['2006-2010 estimate of obesity']\n",
    "\n",
    "# definitions for the axes\n",
    "left, width = 0.2, 0.65\n",
    "bottom, height = 0.1, 0.65\n",
    "spacing = 0.005\n",
    "\n",
    "\n",
    "rect_scatter = [left, bottom, width, height]\n",
    "rect_histx = [left, bottom + height + spacing, width, 0.2]\n",
    "rect_histy = [left + width + spacing, bottom, 0.2, height]\n",
    "\n",
    "# start with a rectangular Figure\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax_scatter = plt.axes(rect_scatter)\n",
    "ax_scatter.tick_params(direction='in', top=True, right=True)\n",
    "ax_histx = plt.axes(rect_histx)\n",
    "ax_histx.tick_params(direction='in', labelbottom=False)\n",
    "ax_histy = plt.axes(rect_histy)\n",
    "ax_histy.tick_params(direction='in', labelleft=False)\n",
    "\n",
    "# the scatter plot:\n",
    "ax_scatter.scatter(x, y)\n",
    "\n",
    "# now determine nice limits by hand:\n",
    "binwidth = 1\n",
    "lim = np.ceil(np.abs(x).max() / binwidth) * binwidth\n",
    "ax_scatter.set_xlim((0, lim))\n",
    "ax_scatter.set_ylim((0, 0.6))\n",
    "\n",
    "bins = np.arange(0, lim + binwidth, binwidth)\n",
    "ax_histx.hist(x, bins=bins)\n",
    "ax_histy.hist(y, bins=20, orientation='horizontal')\n",
    "\n",
    "ax_histx.set_xlim(ax_scatter.get_xlim())\n",
    "ax_histy.set_ylim(ax_scatter.get_ylim())\n",
    "\n",
    "ax_scatter.set_ylabel('obesity')\n",
    "ax_scatter.set_xlabel('fast food in census tract')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud\n",
    " \n",
    "Not all data that we want to visualize is best done in a numerical or relationship based visual representation.  An example might be word counts, or word popularity.  Plotting works on a histogram isn't compelling, but a word cloud (maybe) is! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing about word clouds is that we know we don't want to include common words that are used as part of the language structure.  The library we are using calls these stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a word cloud using the lyrics from Imagine.  First we need to load the lyrics into a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagine_lyrics = \"\"\"\n",
    "Imagine there's no countries\n",
    "It isn't hard to do\n",
    "Nothing to kill or die for\n",
    "And no religion, too\n",
    "Imagine all the people\n",
    "Living life in peace\n",
    "You, you may say I'm a dreamer\n",
    "But I'm not the only one\n",
    "I hope someday you will join us\n",
    "And the world will be as one\n",
    "Imagine no possessions\n",
    "I wonder if you can\n",
    "No need for greed or hunger\n",
    "A brotherhood of man\n",
    "Imagine all the people\n",
    "Sharing all the world\n",
    "You, you may say I'm a dreamer\n",
    "But I'm not the only one\n",
    "I hope someday you will join us\n",
    "And the world will live as one\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use the string methods to clean up the text and put the words in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "imagine_lyrics = imagine_lyrics.replace(',', '')\n",
    "imagine_tokens = imagine_lyrics.split() \n",
    "for x in imagine_tokens :\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make all the words lower case so the word cloud doesn't have a mix of upper and lower case letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imagine_tokens)): \n",
    "        imagine_tokens[i] = imagine_tokens[i].lower() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put it all back together in a simple single string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagine_words = ' '\n",
    "for word in imagine_tokens: \n",
    "    imagine_words = imagine_words + word + ' '\n",
    "  \n",
    "imagine_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is creating the actual word cloud...  let's look at the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = set(STOPWORDS), \n",
    "                min_font_size = 10)\n",
    "\n",
    "wordcloud.generate(imagine_words) \n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial visualization\n",
    "\n",
    "Exercise modeled after the example on Geopandas documentation and [GitHub example](https://github.com/bendoesdata/make-a-map-geopandas/blob/master/Let's%20make%20a%20map!%20Geopandas%20and%20Matplotlib.ipynb).\n",
    "\n",
    "GeoPandas is a way to work with geogrpahically encoded data.  It's very powerful, both from a compuation stand point (e.g. compute base on distance or geographic boundry) but also from a visualization stand point (what we will explore in this lecture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df = gpd.read_file('files/pitt_neighborhoods.shp')  # you load the shape file, but the other files are REQUIRED to be in the directory too\n",
    "map_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once loaded, you can plot the map_df to see what's in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load another dataframe that we will merge with the geo-dataframe to produce some geographic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = pd.read_csv(\"files/burgh_crime.csv\")\n",
    "df_crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime_count = df_crime.groupby('INCIDENTNEIGHBORHOOD').count()\n",
    "df_crime_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_merged4 = map_df.merge(df_crime_count, left_on=\"hood\", right_on=\"INCIDENTNEIGHBORHOOD\")\n",
    "map_merged4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a geographic plot is not very complex, just plotting using plot on the geo-dataframe (but it has to be the geo-dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(10, 6))\n",
    "\n",
    "# create map\n",
    "map_merged4.plot(column='OFFENSES', cmap='Blues', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use addition methods and settings to make the visualization look nicer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(10, 6))\n",
    "\n",
    "# create map\n",
    "map_merged4.plot(column=variable, cmap='Blues', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "# add a title\n",
    "ax.set_title('Crime incidents by neighborhood (2016-present)', fontdict={'fontsize': '25', 'fontweight' : '3'})\n",
    "# create an annotation for the data source\n",
    "ax.annotate('Source: Western Pennsylvania Open Data Center, 2020',xy=(0.1, .08),  xycoords='figure fraction', horizontalalignment='left', verticalalignment='top', fontsize=12, color='#555555')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makeing the legend takes a little more effort to know the range of the values being represented/encoded on to the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_merged4['OFFENSES'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the range for the choropleth\n",
    "vmin, vmax = 0, map_merged4['OFFENSES'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(13, 6))\n",
    "\n",
    "# create map\n",
    "map_merged4.plot(column=variable, cmap='Blues', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "# add a title\n",
    "ax.set_title('Crime incidents by neighborhood (2016-present)', fontdict={'fontsize': '25', 'fontweight' : '3'})\n",
    "# create an annotation for the data source\n",
    "ax.annotate('Source: Western Pennsylvania Open Data Center, 2020',xy=(0.1, .08),  xycoords='figure fraction', horizontalalignment='left', verticalalignment='top', fontsize=12, color='#555555')\n",
    "\n",
    "# Create colorbar as a legend\n",
    "sm = plt.cm.ScalarMappable(cmap='Blues', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "# empty array for the data range\n",
    "sm._A = []\n",
    "# add the colorbar to the figure\n",
    "cbar = fig.colorbar(sm)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
